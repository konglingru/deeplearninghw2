[1] Scape: shape completion and animation of people
[2] Realtime multi-person 2d pose estimation using part afﬁnity ﬁelds
[3] A simple framework for contrastive learn- ing of visual representations
[4] Generative approach for prob- abilistic human mesh recovery using diffusion models
[5] Pose2mesh: Graph convolutional network for 3d human pose and mesh recovery from a 2d human pose
[6] Learning to estimate robust 3d human mesh from in-the-wild crowded scenes
[7] Learning to estimate robust 3d human mesh from in-the-wild crowded scenes
[8] Monocular expressive body regression through body-driven attention
[9] An image is worth 16x16 words: Trans- formers for image recognition at scale
[10] Diffpose: Spatiotemporal diffusion model for video-based human pose estimation
[11] Remips: Phys- ically consistent 3d reconstruction of multiple interacting people under weak supervision
[12] Distribution-aligned diffusion for human mesh recovery
[13] Holopose: Holistic 3d human reconstruction in-the-wild
[14] Densepose: Dense human pose estimation in the wild
[15] Deep residual learning for image recognition
[16] Denoising diffu- sion probabilistic models
[17] LoRA: Low-rank adaptation of large language models
[18] Human3
[19] Coherent reconstruction of multiple humans from a single image
[20] Panoptic studio: A massively multiview system for social motion capture
[21] End-to-end recovery of human shape and pose
[22] Oc- cluded human mesh recovery
[23] Vibe: Video inference for human body pose and shape estimation
[24] Pare: Part attention regressor for 3d hu- man body estimation
[25] Learning to reconstruct 3d human pose and shape via model-ﬁtting in the loop
[26] Convolutional mesh regression for single-image hu- man shape reconstruction
[27] Crowdpose: Efﬁcient crowded scenes pose estimation and a new benchmark
[28] Jotr: 3d joint contrastive learning with transformers for occluded human mesh recovery
[29] Cliff: Carrying location information in full frames into human pose and shape estimation
[30] End-to-end hu- man pose and mesh reconstruction with transformers
[31] Microsoft coco: Common objects in context
[32] Swin transformer v2: Scaling up capacity and resolution
[33] Smpl: A skinned multi- person linear model
[34] 3d human mesh estimation from virtual mark- ers
[35] Troje, Ger- ard Pons-Moll, and Michael J
[36] Single-shot multi-person 3d pose estimation from monocular rgb
[37] Poseﬁx: Model-agnostic general human pose reﬁnement net- work
[38] Neuralannot: Neural annotator for 3d human mesh training sets
[39] Learning to estimate 3d human pose and shape from a single color image
[40] A
[41] Learn- ing transferable visual models from natural language super- vision
[42] High-resolution image syn- thesis with latent diffusion models
[43] U-net: Convolutional networks for biomedical image segmentation
[44] Laion-5b: An open large-scale dataset for train- ing next generation image-text models
[45] Deep unsupervised learning using nonequilibrium thermodynamics
[46] Deep high-resolution representation learning for human pose esti- mation
[47] Monocular, one-stage, regression of multiple 3d people
[48] Monocular, one-stage, regression of multiple 3d people
[49] Putting people in their place: Monocular regression of 3d people in depth
[50] Recovering accurate 3d human pose in the wild using imus and a moving camera
[51] Proliﬁcdreamer: High-ﬁdelity and diverse text-to-3d generation with variational score distilla- tion
[52] Monocular 3d pose and shape estimation of multiple people in natural scenes-the importance of multiple scene constraints
[53] Deep network for the in- tegrated 3d sensing of multiple people in natural images
[54] Weakly supervised 3d human pose and shape re- construction with normalizing ﬂows
[55] Pymaf: 3d human pose and shape regression with pyramidal mesh alignment feedback loop
[56] Adding conditional control to text-to-image diffusion models
[57] Object- occluded human shape and pose estimation from a single color image
[58] Unleashing text-to-image diffusion models for visual perception
